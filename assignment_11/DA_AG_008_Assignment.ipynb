{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5efa0000",
      "metadata": {
        "id": "5efa0000"
      },
      "source": [
        "### Question 1\n",
        "**What is Simple Linear Regression (SLR)? Explain its purpose.**\n",
        "\n",
        "- **Simple Linear Regression** (SLR) is a foundational statistical and machine learning technique that models the relationship between two continuous variables: one independent variable (predictor) and one dependent variable (response). The core idea is to fit a straight line to observed data points so that it best represents how the dependent variable changes as the independent variable varies. The line is described by the equation Y =β0+β1X +ϵ, where Y is the output, X is the feature, β0 is the intercept, β1 is the slope, and\n",
        "ϵ captures errors or residuals.\n",
        "- **The purpose** of SLR is to make quantitative predictions, uncover relationships, and forecast outcomes in fields like economics (predicting income by education level), biology, or engineering. SLR enables analysts to estimate the effect of one variable on another and quantify significance using metrics such as R-squared or p-values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56374634",
      "metadata": {
        "id": "56374634"
      },
      "source": [
        "### Question 2\n",
        "**What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "- Linearity: The relationship between independent and dependent variables must be linear; if not, the model's predictive accuracy and interpretability diminish.\n",
        "\n",
        "- Independence: Observations and their error terms should be independent. Violation (like autocorrelation in time series) causes unreliable inference.\n",
        "\n",
        "- Homoscedasticity: The variance of errors should remain constant across all levels of the independent variable. Heteroscedasticity (changing variance) leads to inefficient estimates.\n",
        "\n",
        "- Normality of Errors: The residuals should be normally distributed, important for valid hypothesis testing and confidence intervals.\n",
        "\n",
        "Checking these assumptions via residual plots, statistical tests (e.g., Durbin-Watson for independence), and transformations (e.g., log) is critical in practical regression modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e616c598",
      "metadata": {
        "id": "e616c598"
      },
      "source": [
        "### Question 3\n",
        "**Write the mathematical equation for a simple linear regression model and explain each term.**\n",
        "\n",
        "The mathematical form of a simple linear regression model is:\n",
        "\n",
        "Y = β0 + β1X + ϵ\n",
        "Where:\n",
        "- Y: Dependent variable (or response)—what you aim to predict.\n",
        "- β0: Intercept—the expected value of Y when X=0\n",
        "- β1 : Slope—shows how much Y will change for every one-unit increase in X.\n",
        "- X: Independent variable (or predictor).\n",
        "- ϵ: The error term—captures random variation or noise not explained by the model.\n",
        "\n",
        "Together, these terms quantitatively describe the relationship and allow for hypothesis testing regarding the impact of X on Y using real data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3fecddc",
      "metadata": {
        "id": "c3fecddc"
      },
      "source": [
        "### Question 4\n",
        "**Provide a real-world example where simple linear regression can be applied.**\n",
        "\n",
        "A classic real-world application of simple linear regression is in real estate: predicting the sale price of houses based on their size (square footage). By collecting data from previous transactions, an analyst fits a line where the independent variable is house size and the dependent variable is price. This allows property agents to estimate the expected price of any new house simply by its square footage. Other examples include predicting crop yield by rainfall, employee productivity by hours of concentrated work, and forecasting sales by ad spend. The usability and interpretability of SLR make it widely applicable in these scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb5ad41",
      "metadata": {
        "id": "0cb5ad41"
      },
      "source": [
        "### Question 5\n",
        "**What is the method of least squares in linear regression?**\n",
        "\n",
        "The method of least squares is the algorithmic backbone of linear regression model fitting. It determines the best-fitting line by minimizing the sum of squared differences between actual observed values and their predicted values by the model. Mathematically, this involves solving for values of\n",
        "β0 and β1 that minimize the objective function:\n",
        "$$\n",
        "Sum of Squared Errors = \\sum_{i=1}^{n} (y_i - (\\hat{y_i}))^2 = \\sum_{i=1}^{n} (y_i - (b_0 + b_1x_i))^2\n",
        "$$\n",
        "\n",
        "The least squares estimates are found using calculus (derivatives/equations). This method ensures unique, unbiased estimates and forms the basis of regression in statistics and machine learning for model calibration and solution computation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08af6029",
      "metadata": {
        "id": "08af6029"
      },
      "source": [
        "### Question 6\n",
        "**What is Logistic Regression? How does it differ from Linear Regression?**\n",
        "\n",
        "Logistic regression is a supervised machine learning algorithm used for binary classification problems, not regression. Unlike linear regression which estimates continuous outcomes, logistic regression predicts the probability that a categorical dependent variable takes a particular value—often yes/no or 1/0. It uses the logistic (sigmoid) function to map predictions between 0 and 1:\n",
        "$$\n",
        "P(Y = 1 \\mid X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X)}}\n",
        "$$\n",
        "Key differences include the type of output (probability/classification for logistic vs continuous values for linear), loss function (likelihood for logistic vs squared error for linear), and underlying assumptions. Logistic regression is widely used in medical diagnosis (disease present/absent), credit scoring, and spam detection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d049e8f3",
      "metadata": {
        "id": "d049e8f3"
      },
      "source": [
        "### Question 7\n",
        "**Name and briefly describe three common evaluation metrics for regression models.**\n",
        "Three common evaluation metrics for regression models are:\n",
        "\n",
        "- Mean Squared Error (MSE): The average of squared differences between actual and predicted values. Penalizes larger errors and is sensitive to outliers.\n",
        "\n",
        "- Mean Absolute Error (MAE): The average absolute difference between actual and predicted outcomes. More robust to outliers than MSE but treats all errors equally.\n",
        "\n",
        "- R-squared (Coeff. of Determination): Represents the proportion of variance in the dependent variable explained by the independent variable(s). Higher values indicate the model fits data well.\n",
        "Choosing between these metrics depends on problem context, sensitivity to large errors, and interpretability needs for business or scientific settings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a18bb0f8",
      "metadata": {
        "id": "a18bb0f8"
      },
      "source": [
        "### Question 8\n",
        "**What is the purpose of the R-squared metric in regression analysis?**\n",
        "\n",
        "The R-squared metric (R^2) quantifies how well the regression model explains the variance of the dependent variable. It ranges from 0 to 1, with values closer to 1 indicating that a greater proportion of variance is accounted for by the model.\n",
        "\n",
        "R^2 helps modelers determine explanatory power and whether adding more features improves predictive capacity. It also aids in hypothesis testing and is widely referenced in both statistical reporting and business analytics to justify model selection and performance claims."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40a48972",
      "metadata": {
        "id": "40a48972"
      },
      "source": [
        "### Question 9\n",
        "**Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept. Include your Python code and output in the code box below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0faf9303",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0faf9303",
        "outputId": "20310b7c-a5b2-4e62-812b-5fe4c4681197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 0.6\n",
            "Intercept: 2.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Example Data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "Y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "print('Slope (Coefficient):', model.coef_[0])\n",
        "print('Intercept:', model.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0092443d",
      "metadata": {
        "id": "0092443d"
      },
      "source": [
        "### Question 10\n",
        "**How do you interpret the coefficients in a simple linear regression model?**\n",
        "\n",
        "In simple linear regression, the model coefficient (slope, β1) quantifies the average change in the dependent variable\n",
        "Y for each one-unit increase in the independent variable X. For example, if the coefficient is 2.5, every additional unit in X is associated with a 2.5 unit increase in Y, on average. The intercept (β0) indicates the expected value of Y when X=0. Proper interpretation also requires considering the scale, domain context, significance (t-tests), and confidence intervals to assess reliability. Coefficient interpretation is vital for drawing insights, decision-making, and communicating model results to non-technical stakeholders."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}